{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open labelled data\n",
    "\n",
    "file = open(\"Fake.csv\")\n",
    "df_fakes = pd.read_csv(file)\n",
    "\n",
    "file2 = open(\"True.csv\")\n",
    "df_true = pd.read_csv(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data, 75 percent for training\n",
    "\n",
    "#train\n",
    "train_fakes = df_fakes[\"title\"][:17610]\n",
    "train_true = df_true[\"title\"][:16062]\n",
    "\n",
    "#test\n",
    "test_fakes = df_fakes[\"title\"][17610:]\n",
    "test_true = df_true[\"title\"][16062:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of words for true article titles and fake ones\n",
    "dd_true = defaultdict(Counter)\n",
    "dd_fake = defaultdict(Counter)\n",
    "\n",
    "# fake articles\n",
    "for i, fake_title in enumerate(train_fakes):\n",
    "    # tokenize words\n",
    "    lTokens = []\n",
    "    sToken = \"\"\n",
    "    for c in fake_title:\n",
    "        if re.match(\"[a-zA-Z0-9]\", str(c)) != None or c == \"\\'\" or c == \"_\" or c == '-':\n",
    "            sToken += c\n",
    "        else:\n",
    "            if sToken != \"\":\n",
    "                lTokens.append(sToken)\n",
    "                sToken = \"\"\n",
    "            if c.strip() != \"\":\n",
    "                lTokens.append(str(c.strip()))\n",
    "    if sToken != \"\":\n",
    "        lTokens.append(sToken)\n",
    "\n",
    "    # update word to dictionary\n",
    "    for word in lTokens:\n",
    "        dd_fake[i][word] = dd_fake[i][word] + 1\n",
    "        \n",
    "# true articles\n",
    "for ii, true_title in enumerate(train_true):\n",
    "    # tokenize words\n",
    "    lTokens = []\n",
    "    sToken = \"\"\n",
    "    for c in true_title:\n",
    "        if re.match(\"[a-zA-Z0-9]\", str(c)) != None or c == \"\\'\" or c == \"_\" or c == '-':\n",
    "            sToken += c\n",
    "        else:\n",
    "            if sToken != \"\":\n",
    "                lTokens.append(sToken)\n",
    "                sToken = \"\"\n",
    "            if c.strip() != \"\":\n",
    "                lTokens.append(str(c.strip()))\n",
    "    if sToken != \"\":\n",
    "        lTokens.append(sToken)\n",
    "\n",
    "    # update word to dictionary\n",
    "    for word in lTokens:\n",
    "        dd_true[ii][word] = dd_true[ii][word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = []\n",
    "for tf, tt in zip(test_fakes, test_true):\n",
    "    l = [tf, 0]\n",
    "    l2 = [tt, 1]\n",
    "    all_titles.append(l)\n",
    "    all_titles.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE NAIVE BAYES FROM HERE \n",
    "\n",
    "#Priors\n",
    "total_docs = len(dd_fake) + len(dd_true)\n",
    "prior_fake = len(dd_fake)/total_docs\n",
    "prior_true = len(dd_true)/total_docs\n",
    "\n",
    "#Posteriors Structures Fake\n",
    "total_freq_per_word_fake = Counter()\n",
    "for doc, words in dd_fake.items():\n",
    "    for word, count in words.items():\n",
    "        total_freq_per_word_fake[word] += count       \n",
    "total_freq_fake = sum(total_freq_per_word_fake.values())   \n",
    "\n",
    "#Posteriors Structures True\n",
    "total_freq_per_word_true = Counter()\n",
    "for doc, words in dd_true.items():\n",
    "    for word, count in words.items():\n",
    "        total_freq_per_word_true[word] += count       \n",
    "total_freq_true = sum(total_freq_per_word_true.values())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Classifier Statistics:\n",
      "\n",
      "0.9952380952380953\n",
      "0.9983089064261556\n",
      "0.9921568627450981\n",
      "0.995223377353189\n"
     ]
    }
   ],
   "source": [
    "# TEST CLASSIFIER\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "# TEST with fake titles below first\n",
    "\n",
    "for title in all_titles:\n",
    "    # tokenize words\n",
    "    lTokens = []\n",
    "    sToken = \"\"\n",
    "    for c in title[0]:\n",
    "        if re.match(\"[a-zA-Z0-9]\", str(c)) != None or c == \"\\'\" or c == \"_\" or c == '-':\n",
    "            sToken += c\n",
    "        else:\n",
    "            if sToken != \"\":\n",
    "                lTokens.append(sToken)\n",
    "                sToken = \"\"\n",
    "            if c.strip() != \"\":\n",
    "                lTokens.append(str(c.strip()))\n",
    "    if sToken != \"\":\n",
    "        lTokens.append(sToken)\n",
    "\n",
    "#Classifier\n",
    "    total_prob_fake = 1\n",
    "    total_prob_true = 1\n",
    "    for word in lTokens:\n",
    "\n",
    "        # check Positive Structures\n",
    "        freq_word_fake = total_freq_per_word_fake[word]\n",
    "        word_prob_fake = 0\n",
    "        if freq_word_fake == 0:\n",
    "            word_prob_fake = 0\n",
    "        else:\n",
    "            word_prob_fake = freq_word_fake/total_freq_fake\n",
    "        if word_prob_fake == 0:\n",
    "            word_prob_fake = (np.finfo(float).eps)\n",
    "        total_prob_fake = total_prob_fake * word_prob_fake\n",
    "\n",
    "        #check Negative Structures\n",
    "        freq_word_true = total_freq_per_word_true[word]\n",
    "        word_prob_true = 0\n",
    "        if freq_word_true == 0:\n",
    "            word_prob_true = 0\n",
    "        else:\n",
    "            word_prob_true = freq_word_true/total_freq_true\n",
    "        if word_prob_true == 0:\n",
    "            word_prob_true = (np.finfo(float).eps)\n",
    "        total_prob_true = total_prob_true * word_prob_true\n",
    "\n",
    "    prob_doc_fake = total_prob_fake * prior_fake\n",
    "    prob_doc_true = total_prob_true * prior_true\n",
    "\n",
    "    #pred label\n",
    "    probs = [prob_doc_fake, prob_doc_true]\n",
    "    m = max(probs)\n",
    "    index = probs.index(m)\n",
    "    if index == 0:\n",
    "        pred_label = \"False\"\n",
    "    elif index == 1:\n",
    "        pred_label = \"True\"\n",
    "    \n",
    "    # actual label\n",
    "    if title[1] == 0:\n",
    "        actual_label =\"False\"\n",
    "    if title[1] == 1:\n",
    "        actual_label =\"True\"\n",
    "\n",
    "    \n",
    "    if pred_label == \"False\" and actual_label == \"False\":\n",
    "        TP += 1\n",
    "    if pred_label == \"True\" and actual_label == \"True\":\n",
    "        TN += 1\n",
    "    if pred_label == \"False\" and actual_label == \"True\":\n",
    "        FP += 1\n",
    "    if pred_label == \"True\" and actual_label == \"False\":\n",
    "        FN += 1\n",
    "\n",
    "# Accuracy Calculations\n",
    "print()\n",
    "print(\"Basic Classifier Statistics:\")\n",
    "print()\n",
    "\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1_Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "print(Accuracy)\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "print(F1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORE TESTING, enter list of items:  item == [title, label] 1 for true, 0 for fake\n",
    "\n",
    "def classifier(titles):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # TEST with fake titles below first\n",
    "\n",
    "    for title in titles:\n",
    "        # tokenize words\n",
    "        lTokens = []\n",
    "        sToken = \"\"\n",
    "        for c in title[0]:\n",
    "            if re.match(\"[a-zA-Z0-9]\", str(c)) != None or c == \"\\'\" or c == \"_\" or c == '-':\n",
    "                sToken += c\n",
    "            else:\n",
    "                if sToken != \"\":\n",
    "                    lTokens.append(sToken)\n",
    "                    sToken = \"\"\n",
    "                if c.strip() != \"\":\n",
    "                    lTokens.append(str(c.strip()))\n",
    "        if sToken != \"\":\n",
    "            lTokens.append(sToken)\n",
    "\n",
    "    #Classifier\n",
    "        total_prob_fake = 1\n",
    "        total_prob_true = 1\n",
    "        for word in lTokens:\n",
    "\n",
    "            # check Positive Structures\n",
    "            freq_word_fake = total_freq_per_word_fake[word]\n",
    "            word_prob_fake = 0\n",
    "            if freq_word_fake == 0:\n",
    "                word_prob_fake = 0\n",
    "            else:\n",
    "                word_prob_fake = freq_word_fake/total_freq_fake\n",
    "            if word_prob_fake == 0:\n",
    "                word_prob_fake = (np.finfo(float).eps)\n",
    "            total_prob_fake = total_prob_fake * word_prob_fake\n",
    "\n",
    "            #check Negative Structures\n",
    "            freq_word_true = total_freq_per_word_true[word]\n",
    "            word_prob_true = 0\n",
    "            if freq_word_true == 0:\n",
    "                word_prob_true = 0\n",
    "            else:\n",
    "                word_prob_true = freq_word_true/total_freq_true\n",
    "            if word_prob_true == 0:\n",
    "                word_prob_true = (np.finfo(float).eps)\n",
    "            total_prob_true = total_prob_true * word_prob_true\n",
    "\n",
    "        prob_doc_fake = total_prob_fake * prior_fake\n",
    "        prob_doc_true = total_prob_true * prior_true\n",
    "\n",
    "        #pred label\n",
    "        probs = [prob_doc_fake, prob_doc_true]\n",
    "        m = max(probs)\n",
    "        index = probs.index(m)\n",
    "        if index == 0:\n",
    "            pred_label = \"False\"\n",
    "        elif index == 1:\n",
    "            pred_label = \"True\"\n",
    "\n",
    "        \n",
    "        \n",
    "        # actual label\n",
    "        if title[1] == 0:\n",
    "            actual_label =\"False\"\n",
    "        if title[1] == 1:\n",
    "            actual_label =\"True\"\n",
    "\n",
    "\n",
    "        if pred_label == \"False\" and actual_label == \"False\":\n",
    "            TP += 1\n",
    "        if pred_label == \"True\" and actual_label == \"True\":\n",
    "            TN += 1\n",
    "        if pred_label == \"False\" and actual_label == \"True\":\n",
    "            FP += 1\n",
    "        if pred_label == \"True\" and actual_label == \"False\":\n",
    "            FN += 1\n",
    "        \n",
    "        print(title, pred_label)\n",
    "    # Accuracy Calculations\n",
    "    print()\n",
    "    print(\"Basic Classifier Statistics:\")\n",
    "    print()\n",
    "\n",
    "    Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "    Precision = TP/(TP+FP)\n",
    "    Recall = TP/(TP+FN)\n",
    "    F1_Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "    print(Accuracy)\n",
    "    print(Precision)\n",
    "    print(Recall)\n",
    "    print(F1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"China's Financial Sector\", 1] True\n",
      "['CRAZY PEOPLE like to Lie', 0] False\n",
      "['Congress approves legislation', 1] True\n",
      "\n",
      "Basic Classifier Statistics:\n",
      "\n",
      "0.875\n",
      "1.0\n",
      "0.8\n",
      "0.888888888888889\n"
     ]
    }
   ],
   "source": [
    "# perfect predictions\n",
    "inputt = [[\"China's Financial Sector\", 1], [\"CRAZY PEOPLE like to Lie\",0], \n",
    "         [\"Congress approves legislation\", 1], \n",
    "\n",
    "classifier(inputt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
